{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Synthesize \n",
    "\n",
    "Take the parsed, cleaned data, and synthesize a long-term daily record for the constituents\n",
    "currently going into the model.\n",
    "\n",
    "Specifically, this means\n",
    " - 2000 - 2016\n",
    " - NOx, NH3, OrthoP\n",
    " - False Delta sources, plus the 40+ discharges in the Bay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import six\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime\n",
    "\n",
    "from stompy import utils,filters\n",
    "\n",
    "from stompy.spatial import wkb2shp, proj_utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "compile_dir=\"../outputs/intermediate\"\n",
    "fig_dir=\"../outputs/figures\"\n",
    "output_dir=\"../outputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating daily data from 2000-01-01 to 2016-12-31 for 6210 time points\n"
     ]
    }
   ],
   "source": [
    "date_start=datetime.datetime(2000,1,1)\n",
    "# 2017-05-26: updated end time to end of CY2016\n",
    "date_end  =datetime.datetime(2016,12,31)\n",
    "\n",
    "dn_start=utils.to_dnum(date_start)\n",
    "dn_end  =utils.to_dnum(date_end)\n",
    "\n",
    "dns=np.arange(dn_start,dn_end+1)\n",
    "fmt='%Y-%m-%d'\n",
    "print(\"Generating daily data from %s to %s for %d time points\"%(date_start.strftime(fmt),\n",
    "                                                                date_end.strftime(fmt),\n",
    "                                                                len(dns)))\n",
    "ds=xr.Dataset()\n",
    "ds['time']=utils.to_dt64(dns)\n",
    "ds['dnum']=('time',dns)\n",
    "ds=ds.set_coords('dnum')\n",
    "\n",
    "analytes=['flow',\n",
    "          'NOx_conc','NH3_conc','PO4_conc','Si_conc',\n",
    "          'NOx_load','NH3_load','PO4_load','Si_load']\n",
    "\n",
    "# These match the names of the CSV files\n",
    "site_names=['tesoro','american','sasm','novato','sunnyvale',\n",
    "            'petaluma','rodeo','fs','valero','phillips66',\n",
    "            'vallejo','ebmud','san_mateo','sfo','palo_alto','sausalito',\n",
    "            'south_bayside','ddsd','burlingame','pinole','st_helena',\n",
    "            'yountville','benicia','millbrae','sonoma_valley','napa',\n",
    "            'cccsd','ebda','calistoga','central_marin','lg','west_county_richmond',\n",
    "            'chevron','sf_southeast','shell','mt_view','marin5','san_jose',\n",
    "            'south_sf','ch','treasure_island','false_sj','false_sac' ]\n",
    "ds['site']=( 'site', site_names)\n",
    "\n",
    "# initialize full output array\n",
    "\n",
    "for analyte in analytes:\n",
    "    ds[analyte]=( ['time','site'],\n",
    "             np.nan*np.ones( (len(ds.time),len(ds.site)) ) )\n",
    "\n",
    "# set units for clarity upfront\n",
    "ds.flow.attrs['units']='m3 s-1'\n",
    "\n",
    "ds.NOx_conc.attrs['units']='mg/l N'\n",
    "ds.NH3_conc.attrs['units']='mg/l N'\n",
    "ds.PO4_conc.attrs['units']='mg/l P'\n",
    "ds.Si_conc.attrs['units']='mg/l Si'\n",
    "ds.NOx_load.attrs['units']='kg/day N'\n",
    "ds.NH3_load.attrs['units']='kg/day N'\n",
    "ds.PO4_load.attrs['units']='kg/day P'\n",
    "ds.Si_load.attrs['units']='kg/day Si'\n",
    "\n",
    "# setup flag entries\n",
    "for v in ds.data_vars.keys():\n",
    "    ds[v+'_flag']=( ds[v].dims, np.zeros(ds[v].shape,'i2'))\n",
    "    ds[v].attrs['flags']=v+'_flag'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "FLAG_LOADING_STUDY=1\n",
    "FLAG_HDR=2\n",
    "FLAG_SUMMER_ZERO=4\n",
    "FLAG_SEASONAL_TREND=8\n",
    "FLAG_INTERP=16\n",
    "FLAG_MEAN=32\n",
    "FLAG_CLIPPED=64 # this one actually does get used as a bitmask.\n",
    "\n",
    "flag_bits=['LoadingStudy','HDR','Summer0','Trend','Interp','Mean','Clipped']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No NO2 for false_sj - okay\n",
      "No NO2 for false_sac - okay\n"
     ]
    }
   ],
   "source": [
    "# Read in Loading Study data via one csv per site\n",
    "for site in ds.site: \n",
    "    site=site.item() # get to a str object\n",
    "    # site_idx=list(ds.site).index(site) # 11\n",
    "\n",
    "    csv=pd.read_csv(os.path.join(compile_dir,site+'.csv'),\n",
    "                        parse_dates=['Date'])\n",
    "    csv_dnums=utils.to_dnum(csv.Date)\n",
    "    csv_date_i = np.searchsorted(dns,csv_dnums)\n",
    " \n",
    "    # limit to the overlap between csv dates and output dates\n",
    "    date_valid=(csv_dnums>=dns[0]) & (csv_dnums<dns[-1])\n",
    "\n",
    "    if 1: # FLOW\n",
    "        if 'flow ft3/s' in csv:\n",
    "            flow=0.028316847 * csv['flow ft3/s']\n",
    "        elif 'flow mgd' in csv:\n",
    "            flow=0.043812636 * csv['flow mgd']\n",
    "        else:\n",
    "            assert False\n",
    "        valid=date_valid & ( ~flow.isnull().values)\n",
    "        ds['flow'].sel(site=site)[csv_date_i[valid]] = flow[valid]\n",
    "        ds['flow_flag'].sel(site=site)[csv_date_i[valid]]=FLAG_LOADING_STUDY\n",
    "        flow_valid=valid # used below\n",
    "        \n",
    "    if 1: # NOx:\n",
    "        nox=csv['NO3 mg/L N'].copy()\n",
    "        try:\n",
    "            nox += csv['NO2 mg/L N']\n",
    "        except KeyError:\n",
    "            print(\"No NO2 for %s - okay\"%site)\n",
    "        valid=date_valid & (~nox.isnull().values)\n",
    "\n",
    "        ds['NOx_conc'].sel(site=site)[csv_date_i[valid]]=nox[valid]\n",
    "        ds['NOx_conc_flag'].sel(site=site)[csv_date_i[valid]]=FLAG_LOADING_STUDY\n",
    "\n",
    "        def conc_to_load(fld='NOx',flag=FLAG_LOADING_STUDY):\n",
    "            flow_valid=ds['flow_flag'].sel(site=site).values==flag\n",
    "            conc_valid=ds[fld+'_conc_flag'].sel(site=site).values==flag\n",
    "            \n",
    "            # and associated load:\n",
    "            load_valid=conc_valid & flow_valid\n",
    "            #     mg/L              m3/s\n",
    "            load= (  ds[fld+'_conc'].sel(site=site).values[load_valid] \n",
    "                   * ds['flow'].sel(site=site).values[load_valid] )\n",
    "            #   ...  L/m3   s/day   kg/mg  \n",
    "            load *= 1e3  * 86400 * 1e-6\n",
    "            ds[fld+'_load'].sel(site=site)[load_valid]=load\n",
    "            ds[fld+'_load_flag'].sel(site=site)[load_valid]=flag\n",
    "        conc_to_load('NOx',FLAG_LOADING_STUDY)\n",
    "        \n",
    "    if 1: # NH3\n",
    "        nh3=csv['NH3 mg/L N']\n",
    "        valid=date_valid & (~nh3.isnull().values)\n",
    "\n",
    "        ds['NH3_conc'].sel(site=site)[csv_date_i[valid]]=nh3[valid]\n",
    "        ds['NH3_conc_flag'].sel(site=site)[csv_date_i[valid]]=FLAG_LOADING_STUDY\n",
    "        conc_to_load('NH3',FLAG_LOADING_STUDY)\n",
    "        \n",
    "    if 1: # PO4\n",
    "        po4=csv['PO4 mg/L P']\n",
    "        valid=date_valid & (~po4.isnull().values)\n",
    "\n",
    "        ds['PO4_conc'].sel(site=site)[csv_date_i[valid]]=po4[valid]\n",
    "        ds['PO4_conc_flag'].sel(site=site)[csv_date_i[valid]]=FLAG_LOADING_STUDY\n",
    "        conc_to_load('PO4',FLAG_LOADING_STUDY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def bin_mean(bins,values):\n",
    "    sums=np.bincount(bins,weights=values)\n",
    "    counts=np.bincount(bins)\n",
    "    return sums/counts\n",
    "\n",
    "\n",
    "def mark_gaps(dnums,valid,gap_days,yearday_start=-1,yearday_end=367,include_ends=False):\n",
    "    \"\"\"\n",
    "    for a timeseries, assumed to be dense and daily,\n",
    "    return a mask which is true for gaps in valid data\n",
    "    which span at least gap_days, limited to the portion of \n",
    "    the year given by yearday_start,yearday_end.\n",
    "    include_ends: include the possibility of a gap of gap_days//2 at the beginning\n",
    "    and end of the series (i.e. as if the next valid data point were very far off\n",
    "    the end of the series)\n",
    "    \"\"\"\n",
    "    doy=np.array([d - utils.dnum_jday0(d)\n",
    "                  for d in dnums] )\n",
    "\n",
    "    missing=~valid\n",
    "    in_window=(doy>=yearday_start)&(doy<yearday_end)\n",
    "    present=np.nonzero( ~missing | ~in_window)[0]\n",
    "\n",
    "    mask=np.zeros( len(dnums),np.bool )\n",
    "\n",
    "    for gstart,gend in zip( present[:-1],present[1:] ):\n",
    "        if gend-gstart<gap_days:\n",
    "            continue\n",
    "        mask[ gstart+gap_days//2 : gend-gap_days//2 ] = True\n",
    "        \n",
    "    if include_ends:\n",
    "        # too tired to think through the logic of how the ends combined with\n",
    "        # the yeardays.\n",
    "        assert yearday_start<0\n",
    "        assert yearday_end>366\n",
    "        first_gap=max(0,present[0]-gap_days//2)\n",
    "        mask[:first_gap]=True\n",
    "        final_gap=min( len(mask), present[-1]+gap_days//2 )\n",
    "        mask[final_gap:]=True\n",
    "    return mask\n",
    "    \n",
    "def add_summer_noflow(site,gap_days=45,day_start=100,day_end=305):\n",
    "    \"\"\" Designed for Napa, but possibly extend to others.\n",
    "    Gaps of more than gap_days, which fall within the period\n",
    "    dayofyear between [day_start,day_end] are filled with zero \n",
    "    flow.\n",
    "    \"\"\"\n",
    "    gap_mask = mark_gaps(dns, \n",
    "                         np.isfinite( ds['flow'].sel(site=site).values ),\n",
    "                         gap_days=gap_days,\n",
    "                         yearday_start=day_start,\n",
    "                         yearday_end=day_end)\n",
    "    ds.flow.sel(site=site).values[gap_mask] = 0\n",
    "    ds.flow_flag.sel(site=site).values[gap_mask] = FLAG_SUMMER_ZERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# special handling of Napa with typically no flow in summer\n",
    "add_summer_noflow(site='napa',gap_days=45,day_start=100,day_end=305)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Peak at HDR Data</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analyte</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>site</th>\n",
       "      <th>value</th>\n",
       "      <th>dn_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flow_mgd</td>\n",
       "      <td>2012</td>\n",
       "      <td>7.0</td>\n",
       "      <td>San Pablo Bay</td>\n",
       "      <td>15.989105</td>\n",
       "      <td>734685.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flow_mgd</td>\n",
       "      <td>2012</td>\n",
       "      <td>8.0</td>\n",
       "      <td>San Pablo Bay</td>\n",
       "      <td>15.852014</td>\n",
       "      <td>734716.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flow_mgd</td>\n",
       "      <td>2012</td>\n",
       "      <td>9.0</td>\n",
       "      <td>San Pablo Bay</td>\n",
       "      <td>15.340764</td>\n",
       "      <td>734747.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flow_mgd</td>\n",
       "      <td>2012</td>\n",
       "      <td>10.0</td>\n",
       "      <td>San Pablo Bay</td>\n",
       "      <td>21.317394</td>\n",
       "      <td>734777.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flow_mgd</td>\n",
       "      <td>2012</td>\n",
       "      <td>11.0</td>\n",
       "      <td>San Pablo Bay</td>\n",
       "      <td>48.396282</td>\n",
       "      <td>734808.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    analyte  year  month           site      value  dn_start\n",
       "0  flow_mgd  2012    7.0  San Pablo Bay  15.989105  734685.0\n",
       "1  flow_mgd  2012    8.0  San Pablo Bay  15.852014  734716.0\n",
       "2  flow_mgd  2012    9.0  San Pablo Bay  15.340764  734747.0\n",
       "3  flow_mgd  2012   10.0  San Pablo Bay  21.317394  734777.0\n",
       "4  flow_mgd  2012   11.0  San Pablo Bay  48.396282  734808.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the HDR data in long format\n",
    "hdr_fn=os.path.join(compile_dir,'hdr_parsed_long.csv')\n",
    "hdr=pd.read_csv(hdr_fn)\n",
    "month_starts=[ datetime.datetime(year=int(r.year),month=int(r.month),day=1)\n",
    "               for ri,r in hdr.iterrows()]\n",
    "hdr['dn_start']=utils.to_dnum( np.array(month_starts))\n",
    "display(HTML('<h3>Peak at HDR Data</h3>'))\n",
    "hdr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# bring in HDR data\n",
    "sites=hdr.site.unique()\n",
    "site_map=dict(zip(sites,[s.lower() for s in sites]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sites which had no HDR data: tesoro, valero, phillips66, st_helena, yountville, calistoga, chevron, shell, false_sj, false_sac\n"
     ]
    }
   ],
   "source": [
    "site_map['American Canyon']='american'\n",
    "site_map['CMSA']='central_marin'\n",
    "site_map['Delta Diablo']='ddsd'\n",
    "site_map['Fairfield-Suisun']='fs'\n",
    "site_map['Las Gallinas']='lg'\n",
    "site_map['Mt View']='mt_view'\n",
    "site_map['Palo Alto']='palo_alto'\n",
    "site_map['San Jose/Santa Clara']='san_jose'\n",
    "site_map['San Mateo']='san_mateo'\n",
    "site_map['SFO Airport']='sfo'\n",
    "site_map['SFPUC Southeast Plant']='sf_southeast'\n",
    "site_map['Sonoma Valley']='sonoma_valley'\n",
    "site_map['South SF']='south_sf'\n",
    "site_map['Treasure Island']='treasure_island'\n",
    "site_map['West County']='west_county_richmond'\n",
    "site_map['SVCW']='south_bayside' # silicon valley clean water - new name for south_bayside\n",
    "site_map['SMCSD']= 'sausalito' # \n",
    "site_map['Crockett CSD Port Costa'] = 'ch' # right?\n",
    "\n",
    "# These are in the HDR data, but ambiguous in the loading study:\n",
    "#  Tiburon, Paradise Cove.  Both are ostensibly Marin SD 5.  Paradise Cove\n",
    "#  has extremely small flows in the HDR data.  Tiburon is a good match for\n",
    "#  the constant values in the Loading Study.\n",
    "site_map['Tiburon'] = 'marin5'\n",
    "# site_map['Paradise Cove']= 'marin5'# but Tiburon is also Marin SD 5...\n",
    "\n",
    "# These are in the Loading study, but not HDR:\n",
    "# refineries: tesoro, valero, phillips66, chevron, shell\n",
    "# potws: st_helena, yountville, calistoga - all up Napa, right?\n",
    "# false: false_sj, false_sac\n",
    "\n",
    "unmapped = [site.item() for site in ds.site\n",
    "            if site.item() not in site_map.values()]\n",
    "print(\"Sites which had no HDR data: %s\"%( \", \".join(unmapped) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write out site_map so that the sidestream code can use the same mapping:\n",
    "import pickle\n",
    "with open('sites_hdr_to_local.pkl','wb') as fp:\n",
    "    pickle.dump(site_map,fp)\n",
    "\n",
    "pd.Series(site_map).to_csv('sites_hdr_to_local.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Millbrae => millbrae\n",
      "Novato => novato\n",
      "CCCSD => cccsd\n",
      "South SF => south_sf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rusty/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:37: RuntimeWarning: invalid value encountered in divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American Canyon => american\n",
      "Tiburon => marin5\n",
      "Napa => napa\n",
      "San Mateo => san_mateo\n",
      "Benicia => benicia\n",
      "Burlingame => burlingame\n",
      "Treasure Island => treasure_island\n",
      "SMCSD => sausalito\n",
      "EBDA => ebda\n",
      "Mt View => mt_view\n",
      "San Jose/Santa Clara => san_jose\n",
      "Fairfield-Suisun => fs\n",
      "SASM => sasm\n",
      "SVCW => south_bayside\n",
      "SFPUC Southeast Plant => sf_southeast\n",
      "EBMUD => ebmud\n",
      "Vallejo => vallejo\n",
      "Crockett CSD Port Costa => ch\n",
      "Las Gallinas => lg\n",
      "Delta Diablo => ddsd\n",
      "SFO Airport => sfo\n",
      "Rodeo => rodeo\n",
      "Petaluma => petaluma\n",
      "Sunnyvale => sunnyvale\n",
      "Palo Alto => palo_alto\n",
      "CMSA => central_marin\n",
      "West County => west_county_richmond\n",
      "Pinole => pinole\n",
      "Sonoma Valley => sonoma_valley\n"
     ]
    }
   ],
   "source": [
    "for hdr_name,ls_name in six.iteritems(site_map):\n",
    "    if ls_name not in list(ds.site.values):\n",
    "        continue\n",
    "    print( \"%s => %s\"%(hdr_name,ls_name))\n",
    "    hdr_site = hdr[ hdr.site==hdr_name ]\n",
    "\n",
    "    # move the analytes back to columns\n",
    "    hdr_site = hdr_site.pivot(index='dn_start',columns='analyte',values='value').reset_index()\n",
    "    dn_end=np.zeros(len(hdr_site.dn_start.values),'f8')\n",
    "    dn_end[:-1]=hdr_site.dn_start.values[1:]\n",
    "    dn_end[-1] = hdr_site.dn_start.values[-1] + 31\n",
    "    hdr_site['dn_end']=dn_end\n",
    "    hdr_site.head()\n",
    "\n",
    "    for ri,r in hdr_site.iterrows():\n",
    "        time_slc=slice(*np.searchsorted(ds.dnum,[r.dn_start,r.dn_end]))\n",
    "\n",
    "        ds_site = ds.sel(site=site_map[hdr_name])\n",
    "\n",
    "        def from_hdr(ds_fld,hdr_fld,factor=1):    \n",
    "            ds_site[ds_fld].values[time_slc] = r[hdr_fld] * factor\n",
    "            ds_site[ds_fld+'_flag'].values[time_slc] = FLAG_HDR\n",
    "\n",
    "        # overwrite with HDR data, constant over month\n",
    "\n",
    "        from_hdr('flow','flow_mgd',0.043812636)\n",
    "        from_hdr('NOx_load','NOx_kgN_per_day',1)\n",
    "        from_hdr('NH3_load','ammonia_kgN_per_day',1)\n",
    "        # unclear whether we should go with diss_OrthoP, or total_kgP ...\n",
    "        from_hdr('PO4_load','diss_OrthoP_kgP_per_day')\n",
    "\n",
    "        # and the conversion to conc:\n",
    "        def to_conc(ds_fld):\n",
    "            flow = ds_site['flow'].values[time_slc] # m3/s\n",
    "            load = ds_site[ds_fld+'_load'].values[time_slc] # kg X / day\n",
    "            # convert to g/m3\n",
    "            conc = (load * 1000) / (flow*86400)\n",
    "            conc[ flow==0.0] = 0.0\n",
    "            #    (kgX/d) * g/kg / (m3/s * s/day) => gX / m3\n",
    "            ds_site[ds_fld+'_conc'].values[time_slc] = conc\n",
    "            ds_site[ds_fld+'_conc_flag'].values[time_slc] = FLAG_HDR\n",
    "\n",
    "        to_conc('NOx')\n",
    "        to_conc('NH3')\n",
    "        to_conc('PO4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site: tesoro\n",
      "   field: flow  3988/6210 valid input points \n",
      "   field: NOx_conc  28/6210 valid input points \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rusty/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: RuntimeWarning: invalid value encountered in divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   field: NH3_conc  192/6210 valid input points \n",
      "   field: PO4_conc  3959/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  28/6210 valid input points \n",
      "   field: NH3_load  192/6210 valid input points \n",
      "   field: PO4_load  3959/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: american\n",
      "   field: flow  1606/6210 valid input points \n",
      "   field: NOx_conc  1156/6210 valid input points \n",
      "   field: NH3_conc  1300/6210 valid input points \n",
      "   field: PO4_conc  1300/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  1156/6210 valid input points \n",
      "   field: NH3_load  1300/6210 valid input points \n",
      "   field: PO4_load  1300/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: sasm\n",
      "   field: flow  1606/6210 valid input points \n",
      "   field: NOx_conc  1462/6210 valid input points \n",
      "   field: NH3_conc  1606/6210 valid input points \n",
      "   field: PO4_conc  1606/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  1462/6210 valid input points \n",
      "   field: NH3_load  1606/6210 valid input points \n",
      "   field: PO4_load  1606/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: novato\n",
      "   field: flow  2492/6210 valid input points \n",
      "   field: NOx_conc  1431/6210 valid input points \n",
      "   field: NH3_conc  1763/6210 valid input points \n",
      "   field: PO4_conc  2462/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  1431/6210 valid input points \n",
      "   field: NH3_load  1763/6210 valid input points \n",
      "   field: PO4_load  2461/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: sunnyvale\n",
      "   field: flow  2957/6210 valid input points \n",
      "   field: NOx_conc  2065/6210 valid input points \n",
      "   field: NH3_conc  2942/6210 valid input points \n",
      "   field: PO4_conc  1613/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  2065/6210 valid input points \n",
      "   field: NH3_load  2942/6210 valid input points \n",
      "   field: PO4_load  1613/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: petaluma\n",
      "   field: flow  1606/6210 valid input points \n",
      "   field: NOx_conc  1462/6210 valid input points \n",
      "   field: NH3_conc  1606/6210 valid input points \n",
      "   field: PO4_conc  1606/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  1462/6210 valid input points \n",
      "   field: NH3_load  1606/6210 valid input points \n",
      "   field: PO4_load  1606/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: rodeo\n",
      "   field: flow  1606/6210 valid input points \n",
      "   field: NOx_conc  1462/6210 valid input points \n",
      "   field: NH3_conc  1606/6210 valid input points \n",
      "   field: PO4_conc  1606/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  1462/6210 valid input points \n",
      "   field: NH3_load  1606/6210 valid input points \n",
      "   field: PO4_load  1606/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: fs\n",
      "   field: flow  2842/6210 valid input points \n",
      "   field: NOx_conc  1516/6210 valid input points \n",
      "   field: NH3_conc  1862/6210 valid input points \n",
      "   field: PO4_conc  2842/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  1516/6210 valid input points \n",
      "   field: NH3_load  1862/6210 valid input points \n",
      "   field: PO4_load  2842/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: valero\n",
      "   field: flow  171/6210 valid input points \n",
      "   field: NOx_conc  25/6210 valid input points \n",
      "   field: NH3_conc  169/6210 valid input points \n",
      "   field: PO4_conc  144/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  25/6210 valid input points \n",
      "   field: NH3_load  169/6210 valid input points \n",
      "   field: PO4_load  144/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: phillips66\n",
      "   field: flow  178/6210 valid input points \n",
      "   field: NOx_conc  28/6210 valid input points \n",
      "   field: NH3_conc  100/6210 valid input points \n",
      "   field: PO4_conc  150/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  28/6210 valid input points \n",
      "   field: NH3_load  100/6210 valid input points \n",
      "   field: PO4_load  150/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: vallejo\n",
      "   field: flow  3156/6210 valid input points \n",
      "   field: NOx_conc  1600/6210 valid input points \n",
      "   field: NH3_conc  3154/6210 valid input points \n",
      "   field: PO4_conc  3156/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  1600/6210 valid input points \n",
      "   field: NH3_load  3154/6210 valid input points \n",
      "   field: PO4_load  3156/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: ebmud\n",
      "   field: flow  5568/6210 valid input points \n",
      "   field: NOx_conc  1462/6210 valid input points \n",
      "   field: NH3_conc  1910/6210 valid input points \n",
      "   field: PO4_conc  5824/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  1462/6210 valid input points \n",
      "   field: NH3_load  1817/6210 valid input points \n",
      "   field: PO4_load  5568/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: san_mateo\n",
      "   field: flow  1567/6210 valid input points \n",
      "   field: NOx_conc  1462/6210 valid input points \n",
      "   field: NH3_conc  1498/6210 valid input points \n",
      "   field: PO4_conc  1567/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  1462/6210 valid input points \n",
      "   field: NH3_load  1498/6210 valid input points \n",
      "   field: PO4_load  1567/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: sfo\n",
      "   field: flow  1606/6210 valid input points \n",
      "   field: NOx_conc  1462/6210 valid input points \n",
      "   field: NH3_conc  1606/6210 valid input points \n",
      "   field: PO4_conc  1606/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  1462/6210 valid input points \n",
      "   field: NH3_load  1606/6210 valid input points \n",
      "   field: PO4_load  1606/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: palo_alto\n",
      "   field: flow  5598/6210 valid input points \n",
      "   field: NOx_conc  1522/6210 valid input points \n",
      "   field: NH3_conc  1979/6210 valid input points \n",
      "   field: PO4_conc  1594/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  1522/6210 valid input points \n",
      "   field: NH3_load  1979/6210 valid input points \n",
      "   field: PO4_load  1594/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: sausalito\n",
      "   field: flow  1606/6210 valid input points \n",
      "   field: NOx_conc  1462/6210 valid input points \n",
      "   field: NH3_conc  1606/6210 valid input points \n",
      "   field: PO4_conc  1606/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  1462/6210 valid input points \n",
      "   field: NH3_load  1606/6210 valid input points \n",
      "   field: PO4_load  1606/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: south_bayside\n",
      "   field: flow  5902/6210 valid input points \n",
      "   field: NOx_conc  1462/6210 valid input points \n",
      "   field: NH3_conc  2014/6210 valid input points \n",
      "   field: PO4_conc  5904/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  1462/6210 valid input points \n",
      "   field: NH3_load  2014/6210 valid input points \n",
      "   field: PO4_load  5902/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: ddsd\n",
      "   field: flow  1605/6210 valid input points \n",
      "   field: NOx_conc  1467/6210 valid input points \n",
      "   field: NH3_conc  1509/6210 valid input points \n",
      "   field: PO4_conc  1605/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  1467/6210 valid input points \n",
      "   field: NH3_load  1509/6210 valid input points \n",
      "   field: PO4_load  1605/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: burlingame\n",
      "   field: flow  1606/6210 valid input points \n",
      "   field: NOx_conc  1462/6210 valid input points \n",
      "   field: NH3_conc  1606/6210 valid input points \n",
      "   field: PO4_conc  1606/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  1462/6210 valid input points \n",
      "   field: NH3_load  1606/6210 valid input points \n",
      "   field: PO4_load  1606/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: pinole\n",
      "   field: flow  1566/6210 valid input points \n",
      "   field: NOx_conc  1426/6210 valid input points \n",
      "   field: NH3_conc  1524/6210 valid input points \n",
      "   field: PO4_conc  1484/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  1426/6210 valid input points \n",
      "   field: NH3_load  1524/6210 valid input points \n",
      "   field: PO4_load  1474/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: st_helena\n",
      "   field: flow  146/6210 valid input points \n",
      "   field: NOx_conc  2/6210 valid input points \n",
      "Insufficient data for seasonal trends - will fill with sample mean\n",
      "   field: NH3_conc  147/6210 valid input points \n",
      "   field: PO4_conc  144/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  2/6210 valid input points \n",
      "Insufficient data for seasonal trends - will fill with sample mean\n",
      "   field: NH3_load  146/6210 valid input points \n",
      "   field: PO4_load  144/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: yountville\n",
      "   field: flow  150/6210 valid input points \n",
      "   field: NOx_conc  6/6210 valid input points \n",
      "Insufficient data for seasonal trends - will fill with sample mean\n",
      "   field: NH3_conc  150/6210 valid input points \n",
      "   field: PO4_conc  144/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  6/6210 valid input points \n",
      "Insufficient data for seasonal trends - will fill with sample mean\n",
      "   field: NH3_load  150/6210 valid input points \n",
      "   field: PO4_load  144/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: benicia\n",
      "   field: flow  1606/6210 valid input points \n",
      "   field: NOx_conc  1462/6210 valid input points \n",
      "   field: NH3_conc  1606/6210 valid input points \n",
      "   field: PO4_conc  1606/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  1462/6210 valid input points \n",
      "   field: NH3_load  1606/6210 valid input points \n",
      "   field: PO4_load  1606/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: millbrae\n",
      "   field: flow  1606/6210 valid input points \n",
      "   field: NOx_conc  1462/6210 valid input points \n",
      "   field: NH3_conc  1606/6210 valid input points \n",
      "   field: PO4_conc  1606/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  1462/6210 valid input points \n",
      "   field: NH3_load  1606/6210 valid input points \n",
      "   field: PO4_load  1606/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: sonoma_valley\n",
      "   field: flow  6026/6210 valid input points \n",
      "   field: NOx_conc  1462/6210 valid input points \n",
      "   field: NH3_conc  2119/6210 valid input points \n",
      "   field: PO4_conc  6026/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  1462/6210 valid input points \n",
      "   field: NH3_load  2119/6210 valid input points \n",
      "   field: PO4_load  6026/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: napa\n",
      "   field: flow  5315/6210 valid input points \n",
      "   field: NOx_conc  1462/6210 valid input points \n",
      "   field: NH3_conc  1611/6210 valid input points \n",
      "   field: PO4_conc  3772/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  1462/6210 valid input points \n",
      "   field: NH3_load  1611/6210 valid input points \n",
      "   field: PO4_load  3772/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: cccsd\n",
      "   field: flow  5900/6210 valid input points \n",
      "   field: NOx_conc  2053/6210 valid input points \n",
      "   field: NH3_conc  5869/6210 valid input points \n",
      "   field: PO4_conc  5904/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  2053/6210 valid input points \n",
      "   field: NH3_load  5865/6210 valid input points \n",
      "   field: PO4_load  5900/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: ebda\n",
      "   field: flow  5569/6210 valid input points \n",
      "   field: NOx_conc  1462/6210 valid input points \n",
      "   field: NH3_conc  1847/6210 valid input points \n",
      "   field: PO4_conc  5569/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  1462/6210 valid input points \n",
      "   field: NH3_load  1847/6210 valid input points \n",
      "   field: PO4_load  5569/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: calistoga\n",
      "   field: flow  149/6210 valid input points \n",
      "   field: NOx_conc  5/6210 valid input points \n",
      "Insufficient data for seasonal trends - will fill with sample mean\n",
      "   field: NH3_conc  149/6210 valid input points \n",
      "   field: PO4_conc  144/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  5/6210 valid input points \n",
      "Insufficient data for seasonal trends - will fill with sample mean\n",
      "   field: NH3_load  149/6210 valid input points \n",
      "   field: PO4_load  144/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: central_marin\n",
      "   field: flow  6026/6210 valid input points \n",
      "   field: NOx_conc  1462/6210 valid input points \n",
      "   field: NH3_conc  2117/6210 valid input points \n",
      "   field: PO4_conc  6026/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  1462/6210 valid input points \n",
      "   field: NH3_load  2117/6210 valid input points \n",
      "   field: PO4_load  6026/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: lg\n",
      "   field: flow  1606/6210 valid input points \n",
      "   field: NOx_conc  1462/6210 valid input points \n",
      "   field: NH3_conc  1606/6210 valid input points \n",
      "   field: PO4_conc  1606/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  1462/6210 valid input points \n",
      "   field: NH3_load  1606/6210 valid input points \n",
      "   field: PO4_load  1606/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: west_county_richmond\n",
      "   field: flow  4413/6210 valid input points \n",
      "   field: NOx_conc  1462/6210 valid input points \n",
      "   field: NH3_conc  1517/6210 valid input points \n",
      "   field: PO4_conc  4413/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  1462/6210 valid input points \n",
      "   field: NH3_load  1517/6210 valid input points \n",
      "   field: PO4_load  4413/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: chevron\n",
      "   field: flow  1096/6210 valid input points \n",
      "   field: NOx_conc  26/6210 valid input points \n",
      "   field: NH3_conc  68/6210 valid input points \n",
      "   field: PO4_conc  1067/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  26/6210 valid input points \n",
      "   field: NH3_load  68/6210 valid input points \n",
      "   field: PO4_load  1067/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: sf_southeast\n",
      "   field: flow  5422/6210 valid input points \n",
      "   field: NOx_conc  1610/6210 valid input points \n",
      "   field: NH3_conc  1705/6210 valid input points \n",
      "   field: PO4_conc  1549/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  1607/6210 valid input points \n",
      "   field: NH3_load  1703/6210 valid input points \n",
      "   field: PO4_load  1548/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: shell\n",
      "   field: flow  4135/6210 valid input points \n",
      "   field: NOx_conc  28/6210 valid input points \n",
      "   field: NH3_conc  163/6210 valid input points \n",
      "   field: PO4_conc  4105/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  28/6210 valid input points \n",
      "   field: NH3_load  163/6210 valid input points \n",
      "   field: PO4_load  4105/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: mt_view\n",
      "   field: flow  1606/6210 valid input points \n",
      "   field: NOx_conc  1462/6210 valid input points \n",
      "   field: NH3_conc  1606/6210 valid input points \n",
      "   field: PO4_conc  1606/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  1462/6210 valid input points \n",
      "   field: NH3_load  1606/6210 valid input points \n",
      "   field: PO4_load  1606/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: marin5\n",
      "   field: flow  1606/6210 valid input points \n",
      "   field: NOx_conc  823/6210 valid input points \n",
      "   field: NH3_conc  967/6210 valid input points \n",
      "   field: PO4_conc  967/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  823/6210 valid input points \n",
      "   field: NH3_load  967/6210 valid input points \n",
      "   field: PO4_load  967/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: san_jose\n",
      "   field: flow  1612/6210 valid input points \n",
      "   field: NOx_conc  1543/6210 valid input points \n",
      "   field: NH3_conc  1612/6210 valid input points \n",
      "   field: PO4_conc  1591/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  1543/6210 valid input points \n",
      "   field: NH3_load  1612/6210 valid input points \n",
      "   field: PO4_load  1591/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: south_sf\n",
      "   field: flow  4444/6210 valid input points \n",
      "   field: NOx_conc  1462/6210 valid input points \n",
      "   field: NH3_conc  3737/6210 valid input points \n",
      "   field: PO4_conc  4444/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  1462/6210 valid input points \n",
      "   field: NH3_load  3737/6210 valid input points \n",
      "   field: PO4_load  4444/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: ch\n",
      "   field: flow  1606/6210 valid input points \n",
      "   field: NOx_conc  61/6210 valid input points \n",
      "Insufficient data for seasonal trends - will fill with sample mean\n",
      "   field: NH3_conc  782/6210 valid input points \n",
      "   field: PO4_conc  205/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  61/6210 valid input points \n",
      "Insufficient data for seasonal trends - will fill with sample mean\n",
      "   field: NH3_load  782/6210 valid input points \n",
      "   field: PO4_load  205/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: treasure_island\n",
      "   field: flow  1606/6210 valid input points \n",
      "   field: NOx_conc  1462/6210 valid input points \n",
      "   field: NH3_conc  1606/6210 valid input points \n",
      "   field: PO4_conc  1606/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  1462/6210 valid input points \n",
      "   field: NH3_load  1606/6210 valid input points \n",
      "   field: PO4_load  1606/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: false_sj\n",
      "   field: flow  6117/6210 valid input points \n",
      "   field: NOx_conc  149/6210 valid input points \n",
      "   field: NH3_conc  149/6210 valid input points \n",
      "   field: PO4_conc  149/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  149/6210 valid input points \n",
      "   field: NH3_load  149/6210 valid input points \n",
      "   field: PO4_load  149/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n",
      "Site: false_sac\n",
      "   field: flow  6117/6210 valid input points \n",
      "   field: NOx_conc  146/6210 valid input points \n",
      "   field: NH3_conc  147/6210 valid input points \n",
      "   field: PO4_conc  146/6210 valid input points \n",
      "   field: Si_conc  0/6210 valid input points  --SKIPPING--\n",
      "   field: NOx_load  146/6210 valid input points \n",
      "   field: NH3_load  147/6210 valid input points \n",
      "   field: PO4_load  146/6210 valid input points \n",
      "   field: Si_load  0/6210 valid input points  --SKIPPING--\n"
     ]
    }
   ],
   "source": [
    "# The interpolation step - building off of synth_v02.py\n",
    "\n",
    "fields=[s for s in ds.data_vars if not s.endswith('_flag')]\n",
    "\n",
    "lowpass_days=3*365\n",
    "shortgap_days=45 # okay to interpolate a little over a month?\n",
    "\n",
    "# first, create mapping from time index to absolute month\n",
    "dts=utils.to_datetime(dns)\n",
    "absmonth = [12*dt.year + (dt.month-1) for dt in dts]\n",
    "absmonth = np.array(absmonth) - dts[0].year*12\n",
    "month=absmonth%12\n",
    "\n",
    "\n",
    "for site in ds.site.values:\n",
    "    print(\"Site: %s\"%site)\n",
    "    for fld in fields: \n",
    "        fld_in=ds[fld].sel(site=site)\n",
    "        orig_values=fld_in.values\n",
    "        fld_flag=ds[fld+'_flag'].sel(site=site)\n",
    "\n",
    "        prefilled=fld_flag.values & (FLAG_SEASONAL_TREND | FLAG_INTERP | FLAG_MEAN)        \n",
    "        fld_in.values[prefilled]=np.nan # resets the work of this loop in case it's run multiple times\n",
    "        n_valid=np.sum( ~fld_in.isnull())        \n",
    "        \n",
    "        if n_valid==0:\n",
    "            msg=\" --SKIPPING--\"\n",
    "        else:\n",
    "            msg=\"\"\n",
    "        print(\"   field: %s  %d/%d valid input points %s\"%(fld,n_valid,len(fld_in),msg))\n",
    "\n",
    "        if n_valid==0:\n",
    "            continue\n",
    "            \n",
    "        # get the data into a monthly time series before trying to fit seasonal cycle\n",
    "        valid = np.isfinite(fld_in.values)\n",
    "        absmonth_mean=bin_mean(absmonth[valid],fld_in.values[valid])\n",
    "        month_mean=bin_mean(month[valid],fld_in.values[valid])\n",
    "        \n",
    "        if np.sum(np.isfinite(month_mean)) < 12:\n",
    "            print(\"Insufficient data for seasonal trends - will fill with sample mean\")\n",
    "            trend_and_season=np.nanmean(month_mean) * np.ones(len(dns))\n",
    "            t_and_s_flag=FLAG_MEAN\n",
    "        else:\n",
    "            # fit long-term trend and a stationary seasonal cycle\n",
    "            # this removes both the seasonal cycle and the long-term mean,\n",
    "            # leaving just the trend\n",
    "            trend_hf=fld_in.values - month_mean[month]\n",
    "            lp = filters.lowpass_fir(trend_hf,lowpass_days,nan_weight_threshold=0.01)\n",
    "            trend = utils.fill_invalid(lp)\n",
    "            # recombine with the long-term mean and monthly trend \n",
    "            # to get the fill values.\n",
    "            trend_and_season = trend + month_mean[month]\n",
    "            t_and_s_flag=FLAG_SEASONAL_TREND\n",
    "\n",
    "        # long gaps are mostly filled by trend and season\n",
    "        gaps=mark_gaps(dns,valid,shortgap_days,include_ends=True) \n",
    "        fld_in.values[gaps] = trend_and_season[gaps]\n",
    "        fld_flag.values[gaps] = t_and_s_flag\n",
    "\n",
    "        still_missing=np.isnan(fld_in.values)\n",
    "        fld_in.values[still_missing] = utils.fill_invalid(fld_in.values)[still_missing]\n",
    "        fld_flag.values[still_missing] = FLAG_INTERP\n",
    "\n",
    "        # Make sure all flows are nonnegative\n",
    "        negative=fld_in.values<0.0\n",
    "        fld_in.values[negative]=0.0\n",
    "        fld_flag.values[negative] |= FLAG_CLIPPED\n",
    "        if 0: # illustrative plots\n",
    "            fig,ax=plt.subplots()\n",
    "            ax.plot(dns,orig_values,'m-o',label='Measured %s'%fld)\n",
    "            ax.plot(dns,fld_in,'k-',label='Final %s'%fld,zorder=5)\n",
    "            # ax.plot(dns,month_mean[month],'r-',label='Monthly Clim.')\n",
    "            # ax.plot(dns,trend_hf,'b-',label='Trend w/HF')\n",
    "            ax.plot(dns,trend,'g-',lw=3,label='Trend')\n",
    "            ax.plot(dns,trend_and_season,color='orange',label='Trend and season')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample plots of output - disabled for production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     1
    ],
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# build up a little dashboard to see what we've got so far:\n",
    "if 0:\n",
    "    sites=list(ds.site.values)\n",
    "    plot_vars=[s for s in ds.data_vars if not s.endswith('_flag')]\n",
    "    plot_vars\n",
    "\n",
    "    fig,ax=plt.subplots(1,1,figsize=(12,5))\n",
    "    cax=fig.add_axes([0.86,0.1,0.03,0.8])\n",
    "    fig.subplots_adjust(left=0.08,right=0.83)\n",
    "\n",
    "    cmap=gmtColormap.cmap_discretize(cm.jet,7)\n",
    "\n",
    "    def update_plot(site,plot_var):    \n",
    "        ax.cla()\n",
    "        cax.cla()\n",
    "\n",
    "        values=ds[plot_var].sel(site=site).values\n",
    "        if ~np.any( np.isfinite(values)):\n",
    "            print(\"No data\")\n",
    "            return False\n",
    "        ax.plot(ds.time,\n",
    "                ds[plot_var].sel(site=site),'k-')\n",
    "        flags=ds[plot_var+'_flag'].sel(site=site).values\n",
    "\n",
    "        sizes=np.ones(ds.time.values.shape) * 30\n",
    "        sizes[flags==FLAG_INTERP]=10\n",
    "        coll = ax.scatter(ds.time.values,\n",
    "                          ds[plot_var].sel(site=site).values,\n",
    "                          sizes,\n",
    "                          np.log2(flags.clip(1,np.inf)),\n",
    "                          cmap=cmap,\n",
    "                          lw=0,zorder=5,vmin=np.log2(1)-0.5,vmax=np.log2(64)+0.5)\n",
    "        ax.set_ylabel(\"%s (%s)\"%(plot_var,ds[plot_var].attrs['units']))\n",
    "        ax.set_title(site)\n",
    "\n",
    "        cbar=plt.colorbar(coll,cax=cax)\n",
    "        flag_values=np.array([1,2,4,8,16,32,64])\n",
    "        flag_pvalues=np.log2(flag_values)\n",
    "        cbar.set_ticks(flag_pvalues)\n",
    "        cbar.set_ticklabels(flag_bits)\n",
    "        plt.draw()\n",
    "        return True\n",
    "\n",
    "    site='ebmud'\n",
    "    plot_var='flow'\n",
    "    update_plot(site='ebmud',plot_var='flow')\n",
    "    gui=interactive(update_plot,site=sites,plot_var=plot_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     1
    ],
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Auto-generate the full set:\n",
    "if 0: \n",
    "    os.path.exists(fig_dir) or os.mkdir(fig_dir)\n",
    "    for site in sites:\n",
    "        \n",
    "        for plot_var in plot_vars:\n",
    "            if plot_var=='site_type':\n",
    "                continue\n",
    "            print(\"%s, %s\"%(site,plot_var))\n",
    "            if update_plot(site=site,plot_var=plot_var):\n",
    "                fig.savefig(os.path.join(fig_dir,\"full_series-%s-%s.png\"%(site,plot_var)),dpi=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Issues so far:\n",
    "Flow:\n",
    " - american: the old assumption of zero Jun-Nov, 0.12 the rest of the time, is not really born out by the HDR data.  Should we abandon the loading study approach, and just use HDR as a seasonal for the whole time?\n",
    " - sasm: has a long period of constant flow from the loading study - but right now we fill gaps in.  \n",
    " - novato: has some monthly data which maybe should be interpolated at larger time scales than 10 days.  also why is the seasonal signal absent for the first stretch?\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site type false: 2\n",
      "Site type potw: 36\n",
      "Site type refinery: 5\n"
     ]
    }
   ],
   "source": [
    "# Mark the \"types\" of the sites (false, potw, refinery)\n",
    "ds['site_type']=('site',[' '*20]*len(ds.site.values))\n",
    "\n",
    "for s in ['tesoro','phillips66','valero','chevron','shell']:\n",
    "    ds.site_type.loc[s] = 'refinery'\n",
    "for s in ['american','sasm','novato','sunnyvale','petaluma',\n",
    "          'rodeo','fs','vallejo','ebmud','san_mateo','sfo',\n",
    "          'palo_alto','sausalito','south_bayside','ddsd',\n",
    "          'burlingame','pinole','st_helena','yountville',\n",
    "          'benicia','millbrae','sonoma_valley','napa','cccsd',\n",
    "          'ebda','calistoga','central_marin','lg','west_county_richmond',\n",
    "          'sf_southeast','mt_view','marin5','san_jose',\n",
    "          'south_sf','ch','treasure_island']:\n",
    "    ds.site_type.loc[s] = 'potw'\n",
    "for s in ['false_sac','false_sj']:\n",
    "    ds.site_type.loc[s] = 'false'\n",
    "\n",
    "for st in np.unique( ds.site_type.values ):\n",
    "    count =np.sum(ds.site_type==st)\n",
    "    print(\"Site type %s: %d\"%(st,count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assign lat/lon from approx_discharge_locations.shp\n",
    "locs=wkb2shp.shp2geom('../sources/discharge_approx_locations.shp')\n",
    "\n",
    "ds['utm_x']=( ('site',), np.nan * np.ones(len(ds.site)))\n",
    "ds['utm_y']=1*ds.utm_x\n",
    "\n",
    "print(\"Discharges in discharge_approx_locations.shp, but not in sfbay_potw data\")\n",
    "for rec in locs:\n",
    "    if rec['short_name'] not in ds.site.values:\n",
    "        print(\"    '%s'\"%rec['short_name'])\n",
    "        continue\n",
    "    xy=np.array(rec['geom'].centroid)\n",
    "    \n",
    "    ds['utm_x'].loc[ dict(site=rec['short_name']) ]=xy[0]\n",
    "    ds['utm_y'].loc[ dict(site=rec['short_name']) ]=xy[1]\n",
    "\n",
    "missing=ds['site'][ np.isnan(ds['utm_x'].values) ].values\n",
    "if len(missing):\n",
    "    print(\"Sites in sfbay_potw data, but without a location from discharge_approx_locations.shp\")\n",
    "    print(\",\".join(missing))\n",
    "else:\n",
    "    print(\"All site in sfbay_potw matched with a lat/lon\")\n",
    "\n",
    "xy=np.c_[ ds.utm_x, ds.utm_y]\n",
    "ll=proj_utils.mapper('EPSG:26910','WGS84')(xy)\n",
    "ds['latitude']=( ('site',),ll[:,1])\n",
    "ds['longitude']=( ('site',),ll[:,0])\n",
    "ds=ds.set_coords(['utm_x','utm_y','latitude','longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:        (site: 43, time: 6210)\n",
       "Coordinates:\n",
       "  * time           (time) datetime64[ns] 2000-01-01 2000-01-02 2000-01-03 ...\n",
       "    dnum           (time) float64 7.301e+05 7.301e+05 7.301e+05 7.301e+05 ...\n",
       "  * site           (site) |S20 'tesoro' 'american' 'sasm' 'novato' ...\n",
       "    utm_x          (site) float64 5.799e+05 5.632e+05 5.483e+05 5.452e+05 ...\n",
       "    utm_y          (site) float64 4.211e+06 4.226e+06 4.192e+06 4.212e+06 ...\n",
       "    latitude       (site) float64 38.05 38.18 37.87 38.06 37.42 38.21 38.05 ...\n",
       "    longitude      (site) float64 -122.1 -122.3 -122.5 -122.5 -122.0 -122.6 ...\n",
       "Data variables:\n",
       "    flow           (time, site) float64 0.2734 0.07307 0.1241 0.3483 0.7141 ...\n",
       "    NOx_conc       (time, site) float64 1.445 6.147 19.68 10.91 13.53 2.488 ...\n",
       "    NH3_conc       (time, site) float64 11.0 1.063 7.694 5.183 10.6 0.5042 ...\n",
       "    PO4_conc       (time, site) float64 0.06 4.188 3.881 0.8166 3.627 2.761 ...\n",
       "    Si_conc        (time, site) float64 nan nan nan nan nan nan nan nan nan ...\n",
       "    NOx_load       (time, site) float64 30.97 41.0 257.0 230.8 834.8 71.72 ...\n",
       "    NH3_load       (time, site) float64 242.8 5.264 101.0 140.0 654.0 5.357 ...\n",
       "    PO4_load       (time, site) float64 1.417 25.64 40.12 20.58 223.8 33.83 ...\n",
       "    Si_load        (time, site) float64 nan nan nan nan nan nan nan nan nan ...\n",
       "    flow_flag      (time, site) int16 16 8 8 8 16 8 8 8 8 8 16 16 8 8 16 8 ...\n",
       "    NOx_conc_flag  (time, site) int16 8 8 8 8 16 8 8 8 8 8 16 8 8 8 16 8 8 8 ...\n",
       "    NH3_conc_flag  (time, site) int16 16 8 8 8 16 8 8 8 8 8 16 16 8 8 16 8 ...\n",
       "    PO4_conc_flag  (time, site) int16 16 8 8 8 16 8 8 8 8 8 16 16 8 8 16 8 ...\n",
       "    Si_conc_flag   (time, site) int16 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
       "    NOx_load_flag  (time, site) int16 8 8 8 8 16 8 8 8 8 8 16 8 8 8 16 8 8 8 ...\n",
       "    NH3_load_flag  (time, site) int16 16 8 8 8 16 8 8 8 8 8 16 16 8 8 16 8 ...\n",
       "    PO4_load_flag  (time, site) int16 16 8 8 8 16 8 8 8 8 8 16 16 8 8 16 8 ...\n",
       "    Si_load_flag   (time, site) int16 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
       "    site_type      (site) |S20 'refinery' 'potw' 'potw' 'potw' 'potw' 'potw' ..."
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ds.to_netcdf(os.path.join( output_dir,'sfbay_potw.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tesoro\n",
      "american\n",
      "sasm\n",
      "novato\n",
      "sunnyvale\n",
      "petaluma\n",
      "rodeo\n",
      "fs\n",
      "valero\n",
      "phillips66\n",
      "vallejo\n",
      "ebmud\n",
      "san_mateo\n",
      "sfo\n",
      "palo_alto\n",
      "sausalito\n",
      "south_bayside\n",
      "ddsd\n",
      "burlingame\n",
      "pinole\n",
      "st_helena\n",
      "yountville\n",
      "benicia\n",
      "millbrae\n",
      "sonoma_valley\n",
      "napa\n",
      "cccsd\n",
      "ebda\n",
      "calistoga\n",
      "central_marin\n",
      "lg\n",
      "west_county_richmond\n",
      "chevron\n",
      "sf_southeast\n",
      "shell\n",
      "mt_view\n",
      "marin5\n",
      "san_jose\n",
      "south_sf\n",
      "ch\n",
      "treasure_island\n",
      "false_sj\n",
      "false_sac\n"
     ]
    }
   ],
   "source": [
    "# And write an xls file, too.  Reload from disk to ensure consitency.\n",
    "ds=xr.open_dataset(os.path.join(output_dir,'sfbay_potw.nc'))\n",
    "\n",
    "writer = pd.ExcelWriter( os.path.join(output_dir,'sfbay_potw.xlsx'))\n",
    "\n",
    "# Break that out into one sheet per source\n",
    "for site_name in ds.site.values:\n",
    "    print(site_name)\n",
    "    df=ds.sel(site=site_name).to_dataframe()\n",
    "\n",
    "    df.to_excel(writer,site_name)\n",
    "writer.save()\n",
    "\n",
    "## \n",
    "\n",
    "# Need to fix the flag attributes in the netcdf (maybe they are set in the\n",
    "# per-site data which goes to ERDDAP, but not in sfbay_potw.nc?)\n",
    "# Seems that there are some deeper problems - wait and fix the flag situation\n",
    "# when new Delta data comes in.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "nav_menu": {},
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "63px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
